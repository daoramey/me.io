---
layout: single
title: Publications
---

Below is a list of my publications. Click the links to view the PDF, access datasets, or check out the code repositories where available.

---

## <span style="font-size:0.6em;">Nonverbal Dynamics in Dyadic Videoconferencing Interaction: The Role of Video Resolution and Conversational Quality</span> 
<span style="font-size:0.7em;">This paper explores how video resolution and conversational quality influence nonverbal communication during videoconferencing. We analyzed webcam recordings to extract individual nonverbal cues—including body movements, facial expressions, and gaze behavior—and assessed interpersonal synchrony using windowed lagged cross-correlation. The findings reveal that higher video resolution enhances individual expressiveness but may reduce interpersonal synchrony in body movements, while better conversational quality improves facial expression mimicry.</span>  
<span style="font-size:0.65em;">**Citation:**</span>  
<span style="font-size:0.65em;">C. Diao, S. A. Arboleda, and A. Raake. Nonverbal Dynamics in Dyadic Videoconferencing Interaction: The Role of Video Resolution and Conversational Quality. In Proceedings of the 26th International Conference on Multimodal Interaction (ICMI '24), Association for Computing Machinery, New York, NY, USA, 387–396.</span>  
<div style="margin-top: 10px;">
  <a href="https://doi.org/10.1145/3678957.3685733" title="DOI">
    <i class="fas fa-link"></i>
  </a> | 
  <a href="{{ site.baseurl }}/assets/pdfs/publication1.pdf" title="PDF">
    <i class="fas fa-file-pdf"></i>
  </a> | 
  <a href="https://osf.io/5tpmf/" title="Dataset">
    <i class="fas fa-database"></i>
  </a> | 
  <a href="https://github.com/daoramey/Nonverbal-Dynamics-VC-Resolution" title="Code">
    <i class="fas fa-code"></i>
  </a>
</div>

---

## <span style="font-size:0.6em;">Effects of Delay on Nonverbal Behavior and Interpersonal Coordination in Video Conferencing</span>
<span style="font-size:0.7em;">This paper examines the impact of transmission delay on nonverbal behavior and interpersonal coordination during videoconferencing. Webcam recordings were analyzed to extract nonverbal cues and assess how delay disrupts body movement synchrony and facial expression mimicry.</span>  
<span style="font-size:0.65em;">**Citation:**</span>
<span style="font-size:0.65em;">C. Diao, S. A. Arboleda, and A. Raake. Effects of Delay on Nonverbal Behavior and Interpersonal Coordination in Video Conferencing. In 2024 IEEE 26th International Workshop on Multimedia Signal Processing (MMSP), West Lafayette, IN, USA, 2024, pp. 1-6, doi:10.1109/MMSP61759.2024.10743300.</span>

<div style="margin-top: 10px;"> <a href="https://doi.org/10.1109/MMSP61759.2024.10743300" title="DOI"> <i class="fas fa-link"></i> </a> | <a href="{{ site.baseurl }}/assets/pdfs/publication2.pdf" title="PDF"> <i class="fas fa-file-pdf"></i> </a> | <a href="https://osf.io/xgq7d/" title="Dataset"> <i class="fas fa-database"></i> </a> | <a href="https://github.com/daoramey/Nonverbal-Dynamics-VC-Delay" title="Code"> <i class="fas fa-code"></i> </a> </div>

---

## <span style="font-size:0.6em;">An Exploratory Study on the Impact of Varying Levels of Robot Control on Presence in Robot-Mediated Communication</span>
<span style="font-size:0.7em;">In this paper, we investigate how different levels of controlling a telepresence robot (teleoperation, shared control, and no control) influence presence. We collected subjective impressions of presence using the temple presence inventory and performed a thematic content analysis on a post-experiment interview. Our results suggest nuances in perceived presence under different levels of robot control after performing a thematic content analysis. Co-presence can be experienced during teleoperation and shared control, and teleoperation may evoke negative sentiments if it does not provide enough spatial information during navigation.
</span>  
<span style="font-size:0.65em;">**Citation:**</span>
<span style="font-size:0.65em;">S. A. Arboleda, S. Fischedick, C. Diao, K. Richter, H.-M. Gross, and A. Raake. An Exploratory Study on the Impact of Varying Levels of Robot Control on Presence in Robot-Mediated Communication. In 2024 33rd IEEE International Conference on Robot and Human Interactive Communication (ROMAN), Pasadena, CA, USA, 2024, pp. 83-88, doi:10.1109/RO-MAN60168.2024.10731330.</span>

<div style="margin-top: 10px;"> <a href="https://doi.org/10.1109/RO-MAN60168.2024.10731330" title="DOI"> <i class="fas fa-link"></i> </a> | <a href="{{ site.baseurl }}/assets/pdfs/publication3.pdf" title="PDF"> <i class="fas fa-file-pdf"></i> </a> </div>

---

## <span style="font-size:0.6em;">Eyes on the Narrative: Exploring the Impact of Visual Realism and Audio Presentation on Gaze Behavior in AR Storytelling</span>
<span style="font-size:0.7em;">This paper explores how visual realism and audio presentation affect gaze behavior in augmented reality storytelling. It examines how these factors modulate viewer engagement and the synchronization of gaze patterns.</span>  
<span style="font-size:0.65em;">**Citation:**</span>
<span style="font-size:0.65em;">F. Weidner, J. Hartbrich, S. A. Arboleda, C. Kunert, C. Schneiderwind, C. Diao, C. Gerhardt, T. Surdu, W. Broll, S. Werner, and A. Raake. Eyes on the Narrative: Exploring the Impact of Visual Realism and Audio Presentation on Gaze Behavior in AR Storytelling. In Proceedings of the 2024 Symposium on Eye Tracking Research and Applications (ETRA '24), Association for Computing Machinery, New York, NY, USA, Article 11, 1–7, doi:10.1145/3649902.3653344.</span>

<div style="margin-top: 10px;"> <a href="https://doi.org/10.1145/3649902.3653344" title="DOI"> <i class="fas fa-link"></i> </a> | <a href="{{ site.baseurl }}/assets/pdfs/publication4.pdf" title="PDF"> <i class="fas fa-file-pdf"></i> </a> | <a href="https://zenodo.org/records/11545344" title="Supplemental Material"> <i class="fas fa-database"></i> </a> </div>

---

## <span style="font-size:0.6em;">Beyond Looks: A Study on Agent Movement and Audiovisual Spatial Coherence in Augmented Reality</span>
<span style="font-size:0.7em;">In this paper, we investigate the influence of three distinct movement patterns (circle, side-to-side, and standing), two rendering styles (realistic and cartoon), and two types of audio (spatial audio and non-spatial audio) on emotional responses, social presence, appearance and behavior plausibility, audiovisual coherence, and auditory plausibility. To enable that, we conducted a study (N=36) where participants observed an agent reciting a short fictional story.</span>  
<span style="font-size:0.65em;">**Citation:**</span>
<span style="font-size:0.65em;">S. A. Arboleda, C. Kunert, J. Hartbrich, C. Schneiderwind, C. Diao, C. Gerhardt, T. Surdu, W. Broll, S. Werner, and A. Raake. Beyond Looks: A Study on Agent Movement and Audiovisual Spatial Coherence in Augmented Reality. In 2024 IEEE Conference Virtual Reality and 3D User Interfaces (VR), Orlando, FL, USA, 2024, pp. 502-512, doi:10.1109/VR58804.2024.00071.</span>

<div style="margin-top: 10px;"> <a href="https://doi.org/10.1109/VR58804.2024.00071" title="DOI"> <i class="fas fa-link"></i> </a> | <a href="{{ site.baseurl }}/assets/pdfs/publication5.pdf" title="PDF"> <i class="fas fa-file-pdf"></i> </a> | <a href="https://zenodo.org/records/10458343" title="Dataset"> <i class="fas fa-database"></i> </a> </div>

---

## <span style="font-size:0.6em;">Revisiting Videoconferencing QoE: Impact of Network Delay and Resolution as Factors for Social Cue Perceptibility</span>
<span style="font-size:0.7em;">This paper revisits the quality of experience in videoconferencing by examining how network delay and video resolution affect the perceptibility of social cues. It quantifies nonverbal behaviors to determine their impact on interaction quality.</span>  
<span style="font-size:0.65em;">**Citation:**</span>
<span style="font-size:0.65em;">C. Diao, L. Sinani, R. R. Ramachandra Rao, and A. Raake. Revisiting Videoconferencing QoE: Impact of Network Delay and Resolution as Factors for Social Cue Perceptibility. In 2023 15th International Conference on Quality of Multimedia Experience (QoMEX), Ghent, Belgium, 2023, pp. 240-243, doi:10.1109/QoMEX58391.2023.10178483.</span>

<div style="margin-top: 10px;"> <a href="https://doi.org/10.1109/QoMEX58391.2023.10178483" title="DOI"> <i class="fas fa-link"></i> </a> | <a href="{{ site.baseurl }}/assets/pdfs/publication6.pdf" title="PDF"> <i class="fas fa-file-pdf"></i> </a> | <a href="https://github.com/daoramey/nonverbal-cues-extraction" title="Code"> <i class="fas fa-code"></i> </a> </div>

---

## <span style="font-size:0.6em;">A Systematic Review on the Visualization of Avatars and Agents in AR & VR Displayed Using Head-Mounted Displays</span>
<span style="font-size:0.7em;">This systematic review synthesizes current research on the visualization of avatars and agents in augmented and virtual reality, focusing on techniques using head-mounted displays. It evaluates various methods to enhance user experience through effective visualization.</span>  
<span style="font-size:0.65em;">**Citation:**</span>
<span style="font-size:0.65em;">F. Weidner, G. Boettcher, S. A. Arboleda, C. Diao, L. Sinani, C. Kunert, C. Gerhardt, W. Broll, and A. Raake. A Systematic Review on the Visualization of Avatars and Agents in AR & VR Displayed Using Head-Mounted Displays. IEEE Transactions on Visualization and Computer Graphics, vol. 29, no. 5, pp. 2596-2606, May 2023, doi:10.1109/TVCG.2023.3247072.</span>

<div style="margin-top: 10px;"> <a href="https://doi.org/10.1109/TVCG.2023.3247072" title="DOI"> <i class="fas fa-link"></i> </a> | <a href="{{ site.baseurl }}/assets/pdfs/publication7.pdf" title="PDF"> <i class="fas fa-file-pdf"></i> </a> | <a href="https://zenodo.org/records/7525054" title="Supplementary File"> <i class="fas fa-database"></i> </a> </div>
